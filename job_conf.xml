<?xml version="1.0"?>
<job_conf>
    <!-- increase to make ui more responsive for many parallel users -->
    <plugins workers="4">
        <plugin id="slurm" type="runner" load="galaxy.jobs.runners.slurm:SlurmJobRunner">
            <param id="drmaa_library_path">/usr/lib/slurm-drmaa/lib/libdrmaa.so</param>
        </plugin>
        <plugin id="slurmthreaded" type="runner" load="galaxy.jobs.runners.slurm:SlurmJobRunner">
            <param id="drmaa_library_path">/usr/lib/slurm-drmaa/lib/libdrmaa.so</param>
        </plugin>
        <plugin id="local" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner"/>
        <plugin id="localthreaded" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner"/>
    </plugins>

    <!-- docker: no. handler entries must match $GALAXY_HANDLER_NUMPROCS 
    handler will load all plugins per default i.e. no need for <plugin id="..."/> sections
    -->
    <handlers>
        <handler id="handler0"/>
        <handler id="handler1"/>
    </handlers>

    <destinations default="slurm">
        <destination id="local" runner="local">
            <!-- <env file="/galaxy_venv/bin/activate"/> -->
            <param id="local_slots">1</param>
        </destination>
        <destination id="localthreaded" runner="localthreaded">
            <!-- <env file="/galaxy_venv/bin/activate"/> -->
            <param id="local_slots" from_environ="GALAXY_CONFIG_PARALLEL_LOCAL_NTASKS">2</param>
        </destination>
        <destination id="slurm" runner="slurm">
            <!-- <env file="/galaxy_venv/bin/activate"/> -->
            <param id="nativeSpecification">--ntasks=1</param>
        </destination>
        <destination id="slurmthreaded" runner="slurm">
            <!-- <env file="/galaxy_venv/bin/activate"/> -->
            <param id="nativeSpecification" from_environ="GALAXY_CONFIG_PARALLEL_SLURM_PARAMS">--ntasks=2</param>
        </destination>
    </destinations>

    <tools>
        <tool id="cutadapt" destination="slurmthreaded"/>
        <tool id="trim_galore" destination="slurmthreaded"/>
        <tool id="trimmomatic" destination="slurmthreaded"/>
        <tool id="samtools_sort" destination="slurmthreaded"/>
        <tool id="samtools_flagstat" destination="slurmthreaded"/>
        <tool id="samtools_markdup" destination="slurmthreaded"/>
        <tool id="hisat2" destination="slurmthreaded"/>
        <tool id="segemehl" destination="slurmthreaded"/>
        <tool id="bwa" destination="slurmthreaded"/>
        <tool id="featurecounts" destination="slurmthreaded"/>
        <tool id="deseq2" destination="slurmthreaded"/>
        <tool id="sortmerna" destination="slurmthreaded"/>
        <tool id="rcorrector" destination="slurmthreaded"/>
        <tool id="rgrnastar" destination="slurmthreaded"/>
        <tool id="bismark" destination="slurmthreaded"/>
        <tool id="bwameth" destination="slurmthreaded"/>
        <tool id="macs2" destination="slurmthreaded"/>
        <tool id="ncbi_blast_plus" destination="slurmthreaded"/>
        <tool id="blast_rbh" destination="slurmthreaded"/>
        <tool id="canu" destination="slurmthreaded"/>
        <tool id="miniasm" destination="slurmthreaded"/>
        <tool id="unicycler" destination="slurmthreaded"/>
        <tool id="prokka" destination="slurmthreaded"/>
    </tools>

    <limits>
        <limit type="walltime">999999:00:00</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm">999999</limit>
        <limit type="destination_user_concurrent_jobs" id="slurmthreaded">999999</limit>
        <limit type="destination_user_concurrent_jobs" id="local">999999</limit>
        <limit type="destination_user_concurrent_jobs" id="localthreaded">999999</limit>
    </limits>
</job_conf>
